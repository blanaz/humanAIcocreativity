{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd-vX3cavOCt"
      },
      "source": [
        "# **Stable Diffusion for Blanka's thesis** ðŸŽ¨ \n",
        "*...using `ðŸ§¨diffusers`*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYOlvQ1nQL7c"
      },
      "source": [
        "### Setup\n",
        "\n",
        "First, please make sure you are using a GPU runtime to run this notebook, so inference is much faster. If the following command fails, use the `Runtime` menu above and select `Change runtime type`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIrgth7sqFML"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers==0.3.0\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install \"ipywidgets>=7,<8\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You also need to accept the model license before downloading or using the weights. In this post we'll use model version `v1-4`, so you'll need to  visit [its card](https://huggingface.co/CompVis/stable-diffusion-v1-4), read the license and tick the checkbox if you agree. \n",
        "\n",
        "You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens)."
      ],
      "metadata": {
        "id": "1Fcyyt0daU4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As google colab has disabled external widgtes, we need to enable it explicitly. Run the following cell to be able to use `notebook_login`"
      ],
      "metadata": {
        "id": "ou0Ijygormum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "OtrOo8YPoM2b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can login with your user token."
      ],
      "metadata": {
        "id": "BHiV7acka4EY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TRAh8G6sNfA"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NnPOMAqAABv"
      },
      "source": [
        "### Stable Diffusion Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSKWBKFPArKS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# make sure you're logged in with `huggingface-cli login`\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True)  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's move the pipeline to GPU to have faster inference."
      ],
      "metadata": {
        "id": "8MgNzTxwbASv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "LA9myHTxbDhm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connecting to anvil\n",
        "!pip install anvil-uplink\n",
        "import anvil.server\n",
        "anvil.server.connect(\"UPJCXES27WNXQ7VYBWKUWOWQ-2DEO2FXVQQI77LMJ\")"
      ],
      "metadata": {
        "id": "JC8FFNPbt3Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#callable function for anvil\n",
        "from torch import autocast\n",
        "import anvil.media\n",
        "import PIL \n",
        "@anvil.server.callable\n",
        "def image_generation(prompt):\n",
        "  with autocast(\"cuda\"):\n",
        "    image = pipe(prompt, num_inference_steps=50).images[0]\n",
        "  image.show()\n",
        "  image.save(\"my_image.jpg\")\n",
        "  image_converted = anvil.media.from_file('my_image.jpg')\n",
        "  return image_converted"
      ],
      "metadata": {
        "id": "4T0bbTMTt4Ug"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}